{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Shapefiles for Web App - HUC8\n",
    "\n",
    "Inputs: \n",
    "1) Pagg_ReportingUnit.csv.  Contains reportinug unit info from WaDE database.\n",
    "\n",
    "2) WaDECounties.shp.  Shapefile of Unitied State counties.\n",
    "\n",
    "Paring HUC8 to ReportingUnitNativeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed Libararies\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import geopandas as gpd # the library that lets us read in shapefiles\n",
    "pd.set_option('display.max_columns', 999)  # How to display all columns of a Pandas DataFrame in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReportingUnitID</th>\n",
       "      <th>ReportingUnitUUID</th>\n",
       "      <th>ReportingUnitNativeID</th>\n",
       "      <th>ReportingUnitName</th>\n",
       "      <th>ReportingUnitTypeCV</th>\n",
       "      <th>StateCV</th>\n",
       "      <th>EPSGCodeCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>00-01-03</td>\n",
       "      <td>00-01-03</td>\n",
       "      <td>Curlew Valley</td>\n",
       "      <td>Subarea</td>\n",
       "      <td>UT</td>\n",
       "      <td>EPSG:4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>000-01-03</td>\n",
       "      <td>000-01-03</td>\n",
       "      <td>Clear Creek</td>\n",
       "      <td>Subarea</td>\n",
       "      <td>UT</td>\n",
       "      <td>EPSG:4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>00-07-02</td>\n",
       "      <td>00-07-02</td>\n",
       "      <td>Promontory Point</td>\n",
       "      <td>Subarea</td>\n",
       "      <td>UT</td>\n",
       "      <td>EPSG:4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReportingUnitID ReportingUnitUUID ReportingUnitNativeID ReportingUnitName  \\\n",
       "0              254          00-01-03              00-01-03     Curlew Valley   \n",
       "1              255         000-01-03             000-01-03       Clear Creek   \n",
       "2              256          00-07-02              00-07-02  Promontory Point   \n",
       "\n",
       "  ReportingUnitTypeCV StateCV EPSGCodeCV  \n",
       "0             Subarea      UT  EPSG:4326  \n",
       "1             Subarea      UT  EPSG:4326  \n",
       "2             Subarea      UT  EPSG:4326  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set working directory\n",
    "workingDir = \"C:/Users/rjame/Documents/WSWC Documents/Portal Creation Research\"\n",
    "os.chdir(workingDir)\n",
    "\n",
    "# Grab AggreagatedAmounts ReportingUnit.csv file.\n",
    "reportingunits_input = pd.read_csv('Pagg_ReportingUnit.csv')\n",
    "df_1RU = pd.DataFrame(reportingunits_input)\n",
    "df_1RU.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "SourceFiles/HUC8/HUC8_US.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_err.pyx\u001b[0m in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: SourceFiles/HUC8/HUC8_US.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d557286df999>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Grab the HUC8 Shapefile.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshapefile_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SourceFiles/HUC8/HUC8_US.shp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdfs_1HUC8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapefile_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdfs_1HUC8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\geopandas\\io\\file.py\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(filename, bbox, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfiona_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m# In a future Fiona release the crs attribute of features will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fiona\\env.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fiona\\__init__.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m--> 253\u001b[1;33m                            layer=layer, enabled_drivers=enabled_drivers, **kwargs)\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\fiona\\collection.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWritingSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.Session.start\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mfiona/_shim.pyx\u001b[0m in \u001b[0;36mfiona._shim.gdal_open_vector\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDriverError\u001b[0m: SourceFiles/HUC8/HUC8_US.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Grab the HUC8 Shapefile.\n",
    "C:\\Users\\rjame\\Documents\\RShinyAppPractice\\CreateAppShapefiles\\SourceFiles\\HUC8\n",
    "shapefile_input = gpd.read_file('SourceFiles/HUC8/HUC8_US.shp')\n",
    "dfs_1HUC8 = pd.DataFrame(shapefile_input)\n",
    "dfs_1HUC8.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUC8\n",
    "# State: Utah\n",
    "###########################################################################\n",
    "\n",
    "# Create temporal dataframes for state specific and reportingunit type storage\n",
    "# dfs_1HUC8_UT = dfs_1HUC8[(dfs_1HUC8.STATES == 'UT')]\n",
    "dfs_1HUC8_UT = dfs_1HUC8\n",
    "df_1RU_HUC8_UT = df_1RU[(df_1RU.ReportingUnitTypeCV == 'HUC8') & ((df_1RU.StateCV == 'UT'))]\n",
    "\n",
    "# retreive ReportingUnitUUID.\n",
    "ReportingUnitUUIDdict = pd.Series(df_1RU_HUC8_UT.ReportingUnitUUID.values, index = df_1RU_HUC8_UT.ReportingUnitNativeID).to_dict()\n",
    "def retrieveCountyName(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        String1 = colrowValue\n",
    "        try:\n",
    "            outList = ReportingUnitUUIDdict[String1]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "dfs_1HUC8_UT['ReportingUnitUUID'] = dfs_1HUC8_UT.apply(lambda row: retrieveCountyName(row['HUC8']), axis=1)\n",
    "\n",
    "# Merging temporal dataframes into one, using left-join.\n",
    "dfs_1HUC8_UT = pd.merge(dfs_1HUC8_UT, df_1RU_HUC8_UT, left_on='ReportingUnitUUID', right_on='ReportingUnitUUID', how='left')\n",
    "\n",
    "# Creating new output state specific dataframe with fields of interest.\n",
    "dfs_2HUC8_UT = pd.DataFrame() #empty dataframe\n",
    "dfs_2HUC8_UT['OBJECTID'] = dfs_1HUC8_UT.index\n",
    "dfs_2HUC8_UT['Shape'] = 'Polygon'\n",
    "dfs_2HUC8_UT['ReportingUnitID'] = dfs_1HUC8_UT['ReportingUnitID']\n",
    "dfs_2HUC8_UT['ReportingUnitUUID'] = dfs_1HUC8_UT['ReportingUnitUUID']\n",
    "dfs_2HUC8_UT['ReportingUnitNativeID'] = dfs_1HUC8_UT['ReportingUnitNativeID']\n",
    "dfs_2HUC8_UT['ReportingUnitName'] = dfs_1HUC8_UT['ReportingUnitName']\n",
    "dfs_2HUC8_UT['ReportingUnitTypeCV'] = dfs_1HUC8_UT['ReportingUnitTypeCV']\n",
    "dfs_2HUC8_UT['StateCV'] = dfs_1HUC8_UT['StateCV']\n",
    "dfs_2HUC8_UT['Shape_Length'] = dfs_1HUC8_UT['Shape_Leng']\n",
    "dfs_2HUC8_UT['Shape_Area'] = dfs_1HUC8_UT['Shape_Area']\n",
    "dfs_2HUC8_UT['geometry'] = dfs_1HUC8_UT['geometry']\n",
    "\n",
    "# view output\n",
    "dfs_2HUC8_UT.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HUC8\n",
    "# State: CO\n",
    "###########################################################################\n",
    "\n",
    "# Create temporal dataframes for state specific and reportingunit type storage\n",
    "# dfs_1HUC8_CO = dfs_1HUC8[(dfs_1HUC8.STATES == 'CO')]\n",
    "dfs_1HUC8_CO = dfs_1HUC8\n",
    "df_1RU_HUC8_CO = df_1RU[(df_1RU.ReportingUnitTypeCV == 'HUC8') & ((df_1RU.StateCV == 'CO'))]\n",
    "\n",
    "# retreive ReportingUnitUUID.\n",
    "ReportingUnitUUIDdict = pd.Series(df_1RU_HUC8_CO.ReportingUnitUUID.values, index = df_1RU_HUC8_CO.ReportingUnitNativeID).to_dict()\n",
    "def retrieveCountyName(colrowValue):\n",
    "    if colrowValue == '' or pd.isnull(colrowValue):\n",
    "        outList = ''\n",
    "    else:\n",
    "        String1 = colrowValue\n",
    "        try:\n",
    "            outList = ReportingUnitUUIDdict[String1]\n",
    "        except:\n",
    "            outList = ''\n",
    "    return outList\n",
    "dfs_1HUC8_CO['ReportingUnitUUID'] = dfs_1HUC8_CO.apply(lambda row: retrieveCountyName(row['HUC8']), axis=1)\n",
    "\n",
    "# Merging temporal dataframes into one, using left-join.\n",
    "dfs_1HUC8_CO = pd.merge(dfs_1HUC8_CO, df_1RU_HUC8_CO, left_on='ReportingUnitUUID', right_on='ReportingUnitUUID', how='left')\n",
    "\n",
    "# Creating new output state specific dataframe with fields of interest.\n",
    "dfs_2HUC8_CO = pd.DataFrame() #empty dataframe\n",
    "dfs_2HUC8_CO['OBJECTID'] = dfs_1HUC8_CO.index\n",
    "dfs_2HUC8_CO['Shape'] = 'Polygon'\n",
    "dfs_2HUC8_CO['ReportingUnitID'] = dfs_1HUC8_CO['ReportingUnitID']\n",
    "dfs_2HUC8_CO['ReportingUnitUUID'] = dfs_1HUC8_CO['ReportingUnitUUID']\n",
    "dfs_2HUC8_CO['ReportingUnitNativeID'] = dfs_1HUC8_CO['ReportingUnitNativeID']\n",
    "dfs_2HUC8_CO['ReportingUnitName'] = dfs_1HUC8_CO['ReportingUnitName']\n",
    "dfs_2HUC8_CO['ReportingUnitTypeCV'] = dfs_1HUC8_CO['ReportingUnitTypeCV']\n",
    "dfs_2HUC8_CO['StateCV'] = dfs_1HUC8_CO['StateCV']\n",
    "dfs_2HUC8_CO['Shape_Length'] = dfs_1HUC8_CO['Shape_Leng']\n",
    "dfs_2HUC8_CO['Shape_Area'] = dfs_1HUC8_CO['Shape_Area']\n",
    "dfs_2HUC8_CO['geometry'] = dfs_1HUC8_CO['geometry']\n",
    "\n",
    "# view output\n",
    "dfs_2HUC8_CO.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "frames = [dfs_2HUC8_UT, dfs_2HUC8_CO]\n",
    "outdf = pd.concat(frames)\n",
    "outdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NA rows\n",
    "outdf = outdf.dropna(subset=['ReportingUnitID'])\n",
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataframe to a shapefile.\n",
    "# Note: rememeber that shapefiles autofil in fields names, will need to fix field names in app upload.\n",
    "dfsOut = gpd.GeoDataFrame(outdf, geometry='geometry') # covert to geodataframe\n",
    "dfsOut.to_file(\"Processed_Shapefiles/P_WaDEHUC8.shp\") # export shape file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retreive ReportingUnitName (to check results)\n",
    "# ReportingUnitNamedict = pd.Series(df_1RU_County_CA.ReportingUnitName.values, index = df_1RU_County_CA.ReportingUnitName).to_dict()\n",
    "# def retrieveCountyName(colrowValue):\n",
    "#     if colrowValue == '' or pd.isnull(colrowValue):\n",
    "#         outList = ''\n",
    "#     else:\n",
    "#         String1 = colrowValue\n",
    "#         try:\n",
    "#             outList = ReportingUnitNamedict[String1]\n",
    "#         except:\n",
    "#             outList = ''\n",
    "#     return outList\n",
    "# dfs_1County_CA['ReportingUnitName'] = dfs_1County_CA.apply(lambda row: retrieveCountyName(row['NAME']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_1HUC8 = dfs_1HUC8.drop(['geometry'], axis=1)\n",
    "# dfs_1HUC8.to_csv('App2Shapefiles/dfs_1HUC8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
